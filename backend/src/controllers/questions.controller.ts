import { Request, Response } from 'express';
import { openaiClient } from '@/config/openai';
import {
  SYSTEM_PROMPT,
  generateQuestionsPrompt,
} from '@/lib/prompts/generate-questions';
import {
  SYSTEM_PROMPT_SESSIONS,
  generateSessionsPrompt,
} from '@/lib/prompts/generate-sessions';
import {
  SYSTEM_PROMPT_PRODUCT_RESEARCH,
  generateProductResearchSessionsPrompt,
} from '@/lib/prompts/generate-product-research-sessions';
import {
  SYSTEM_PROMPT_MARKET_RESEARCH,
  generateMarketResearchSessionsPrompt,
} from '@/lib/prompts/generate-market-research-sessions';
import {
  SYSTEM_PROMPT_LOCALIZATION,
  generateLocalizeOutlinePrompt,
} from '@/lib/prompts/localize-outline';

export const generateInterviewQuestions = async (req: Request, res: Response) => {
  console.log("generate-interview-questions request received");
  const body = req.body;

  console.warn('ã€OpenAI é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts:15', {
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1",
    requestBody: body
  });

  try {
    const baseCompletion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT,
        },
        {
          role: "user",
          content: generateQuestionsPrompt(body),
        },
      ],
      response_format: { type: "json_object" },
    });

    const basePromptOutput = baseCompletion.choices[0] || {};
    const content = basePromptOutput.message?.content;

    console.log("Interview questions generated successfully");

    res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error generating interview questions:", error);
    console.error('ã€OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts:49', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      requestBody: body
    });

    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

export const generateInterviewSessions = async (req: Request, res: Response) => {
  console.error("ğŸš€ğŸš€ğŸš€ generate-interview-sessions request received ğŸš€ğŸš€ğŸš€");
  const body = req.body;
  console.error("ğŸ“¦ Request body:", JSON.stringify(body, null, 2));
  const researchType = body.researchType || 'product';
  // ä¼˜å…ˆä½¿ç”¨ outline_debug_languageï¼ˆå¤§çº²è°ƒè¯•è¯­è¨€ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ languageï¼ˆè®¿è°ˆè¯­è¨€ï¼‰
  const debugLanguage = body.outline_debug_language || body.language || 'en-US';
  console.error("ğŸŒ Debug Language:", debugLanguage);
  console.error("ğŸŒ Interview Language:", body.language);

  // å°†è°ƒè¯•è¯­è¨€ä¼ é€’ç»™promptç”Ÿæˆå‡½æ•°
  const promptBody = {
    ...body,
    language: debugLanguage
  };

  let systemPrompt;
  let userPrompt;

  if (researchType === 'market') {
    systemPrompt = SYSTEM_PROMPT_MARKET_RESEARCH;
    userPrompt = generateMarketResearchSessionsPrompt(promptBody);
  } else if (researchType === 'product') {
    systemPrompt = SYSTEM_PROMPT_PRODUCT_RESEARCH;
    userPrompt = generateProductResearchSessionsPrompt(promptBody);
  } else {
    systemPrompt = SYSTEM_PROMPT_SESSIONS;
    userPrompt = generateSessionsPrompt(promptBody);
  }

  console.warn('ã€ç”Ÿæˆ Sessions - é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
    researchType,
    debugLanguage, // è®°å½•è°ƒè¯•è¯­è¨€
    interviewLanguage: body.language || 'N/A', // è®°å½•è®¿è°ˆè¯­è¨€
    customInstructions: body.customInstructions || 'none', // è®°å½•ä¸ªæ€§åŒ–å¤‡æ³¨
    context: body.context || 'none', // ğŸ†• è®°å½• context
    contextLength: body.context ? body.context.length : 0, // ğŸ†• è®°å½• context é•¿åº¦
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1",
    requestBody: body
  });

  // ğŸ†• è¾“å‡ºå®é™…å‘é€ç»™ OpenAI çš„å®Œæ•´ prompt
  console.log('==================== ğŸ“ PROMPT SENT TO OPENAI ğŸ“ ====================');
  console.log('ğŸ¤– SYSTEM PROMPT:');
  console.log(systemPrompt);
  console.log('\nğŸ‘¤ USER PROMPT:');
  console.log(userPrompt);
  console.log('==================== ğŸ“ END OF PROMPT ğŸ“ ====================\n');

  try {
    const baseCompletion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      response_format: { type: "json_object" },
    });

    const basePromptOutput = baseCompletion.choices[0] || {};
    let content = basePromptOutput.message?.content;  // ğŸ”§ æ”¹ä¸º letï¼Œä»¥ä¾¿è¡¥å…¨æ—¶æ›´æ–°

    console.log(`Interview sessions (${researchType}) generated successfully`);

    // ğŸ” éªŒè¯ GPT å®é™…ç”Ÿæˆçš„æ•°é‡
    try {
      let parsedContent = JSON.parse(content || '{}');
      const actualCount = parsedContent.questions?.length || 0;
      const requestedCount = Math.min(body.number, 10);
      
      console.log('ğŸ“Š Session Count Verification:', {
        requested: requestedCount,
        actualGenerated: actualCount,
        match: actualCount === requestedCount ? 'âœ…' : 'âŒ',
        questions: parsedContent.questions?.map((q: string, i: number) => ({
          index: i + 1,
          preview: q.substring(0, 50) + '...'
        }))
      });
      
      if (actualCount !== requestedCount) {
        console.error(`âš ï¸âš ï¸âš ï¸ COUNT MISMATCH: Requested ${requestedCount} but GPT generated ${actualCount} sessions!`);
        console.error('ğŸ“ GPT åŸå§‹å›å¤ï¼ˆå®Œæ•´å†…å®¹ï¼‰ï¼š');
        console.error('==================== START ====================');
        console.error(content);
        console.error('==================== END ====================');
        
        // ğŸ”§ æ™ºèƒ½è¡¥å…¨ï¼šå¦‚æœæ•°é‡ä¸è¶³ï¼Œè®© GPT ç»§ç»­è¡¥å…¨
        if (actualCount < requestedCount) {
          const missing = requestedCount - actualCount;
          console.log(`ğŸ”„ è°ƒç”¨ GPT è¡¥å…¨å‰©ä½™ ${missing} ä¸ª sessions...`);
          
          try {
            const complementPrompt = `You previously generated ${actualCount} sessions for an interview guide, but the user requested ${requestedCount} sessions in total.

Here are the ${actualCount} sessions you already generated:
${JSON.stringify(parsedContent.questions, null, 2)}

**CRITICAL REQUIREMENT**:
You MUST now generate EXACTLY ${missing} MORE sessions (Session ${actualCount + 1} to Session ${requestedCount}) to complete the interview guide.

Requirements:
1. Continue from where you left off (start with Session ${actualCount + 1})
2. Generate EXACTLY ${missing} sessions - no more, no less
3. Maintain the same format and quality as the previous sessions
4. Ensure these new sessions naturally follow the previous ones
5. Each session should follow the established structure

Original research context:
- Research Type: ${researchType}
- Study Name: ${body.name}
- Research Objective: ${body.objective}
${body.context ? `- Additional Context: ${body.context}` : ''}

Output ONLY a JSON object with a "questions" array containing EXACTLY ${missing} new session strings.
Format: {"questions": ["session ${actualCount + 1} text", "session ${actualCount + 2} text", ...]}

DO NOT include the previous ${actualCount} sessions in your response.
ONLY generate the NEW ${missing} sessions.`;

            const complementResponse = await openaiClient.chat.completions.create({
              model: "gpt-4o",
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: complementPrompt,
                },
              ],
              response_format: { type: "json_object" },
              temperature: 0.7,
            });

            const complementContent = complementResponse.choices[0]?.message?.content;
            const complementParsed = JSON.parse(complementContent || '{}');
            
            if (complementParsed.questions && Array.isArray(complementParsed.questions)) {
              console.log(`âœ… GPT è¡¥å…¨äº† ${complementParsed.questions.length} ä¸ª sessions`);
              // åˆå¹¶åŸå§‹å’Œè¡¥å…¨çš„ sessions
              parsedContent.questions = [...parsedContent.questions, ...complementParsed.questions];
              content = JSON.stringify(parsedContent);
              console.log(`âœ… æ€»è®¡ ${parsedContent.questions.length} ä¸ª sessions`);
            } else {
              console.error('âŒ GPT è¡¥å…¨å“åº”æ ¼å¼é”™è¯¯');
            }
          } catch (complementError: any) {
            console.error('âŒ GPT è¡¥å…¨å¤±è´¥:', complementError.message);
          }
        } else if (actualCount > requestedCount) {
          // å¦‚æœç”Ÿæˆå¤šäº†ï¼Œç›´æ¥æˆªæ–­
          console.log(`âœ‚ï¸ æˆªæ–­åˆ° ${requestedCount} ä¸ª sessions`);
          parsedContent.questions = parsedContent.questions.slice(0, requestedCount);
          content = JSON.stringify(parsedContent);
        }
      }
    } catch (e) {
      console.error('âŒ Failed to parse GPT response for verification:', e);
      console.error('ğŸ“ GPT åŸå§‹å›å¤ï¼ˆè§£æå¤±è´¥ï¼Œè¾“å‡ºåŸå§‹å†…å®¹ï¼‰ï¼š');
      console.error('==================== START ====================');
      console.error(content);
      console.error('==================== END ====================');
    }

    res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error generating interview sessions:", error);
    console.error('ã€ç”Ÿæˆ Sessions - OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      requestBody: body
    });

    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

/**
 * æœ¬åœ°åŒ–å¤§çº²æ¥å£
 * å°†è°ƒè¯•è¯­è¨€çš„åˆç¨¿å¤§çº²æœ¬åœ°åŒ–åˆ°ç›®æ ‡è®¿è°ˆè¯­è¨€
 */
export const localizeOutline = async (req: Request, res: Response) => {
  console.log("localize-outline request received");
  const body = req.body;

  const {
    draftOutline,
    targetLanguage,
    researchObjective,
    studyName,
    description
  } = body;

  // éªŒè¯å¿…éœ€å‚æ•°
  if (!draftOutline || !targetLanguage) {
    return res.status(400).json({
      error: "Missing required parameters",
      details: "draftOutline and targetLanguage are required"
    });
  }

  console.warn('ã€æœ¬åœ°åŒ–å¤§çº² - é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
    targetLanguage,
    studyName: studyName || 'N/A',
    description: description || 'N/A',  // æ·»åŠ  description æ—¥å¿—
    descriptionLength: description ? description.length : 0,  // description é•¿åº¦
    draftOutlineLength: Array.isArray(draftOutline) ? draftOutline.length : 'invalid',
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1"
  });

  try {
    const completion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT_LOCALIZATION,
        },
        {
          role: "user",
          content: generateLocalizeOutlinePrompt({
            draftOutline,
            targetLanguage,
            researchObjective,
            studyName,
            description
          }),
        },
      ],
      response_format: { type: "json_object" },
      temperature: 0.7, // ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´è‡ªç„¶çš„è¡¨è¾¾
    });

    const output = completion.choices[0] || {};
    const content = output.message?.content;

    console.log(`âœ… Outline localized successfully to ${targetLanguage}`);

    // è§£æå¹¶éªŒè¯ OpenAI å“åº”
    try {
      const parsedContent = JSON.parse(content || '{}');
      console.log('ğŸ“ OpenAI Response Structure:', {
        hasQuestions: !!parsedContent.questions,
        questionsCount: parsedContent.questions?.length || 0,
        hasDescription: !!parsedContent.description,
        descriptionPreview: parsedContent.description ?
          parsedContent.description.substring(0, 100) + '...' :
          'MISSING'
      });

      if (!parsedContent.description) {
        console.warn('âš ï¸ WARNING: OpenAI did not return description field!');
      }
    } catch (e) {
      console.error('âŒ Failed to parse OpenAI response:', e);
    }

    return res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error localizing outline:", error);
    console.error('ã€æœ¬åœ°åŒ–å¤§çº² - OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      targetLanguage,
      requestBody: body
    });

    return res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};
