import { Request, Response } from 'express';
import { openaiClient } from '@/config/openai';
import {
  SYSTEM_PROMPT,
  generateQuestionsPrompt,
} from '@/lib/prompts/generate-questions';
import {
  SYSTEM_PROMPT_PRODUCT_RESEARCH,
  generateProductResearchSessionsPrompt,
} from '@/lib/prompts/generate-product-research-sessions';
import {
  SYSTEM_PROMPT_MARKET_RESEARCH,
  generateMarketResearchSessionsPrompt,
} from '@/lib/prompts/generate-market-research-sessions';
import {
  SYSTEM_PROMPT_LOCALIZATION,
  generateLocalizeOutlinePrompt,
} from '@/lib/prompts/localize-outline';
import {
  SYSTEM_PROMPT_SKELETON,
  generateSkeletonPrompt,
} from '@/lib/prompts/generate-outline-skeleton';
import {
  SYSTEM_PROMPT_FULL_OUTLINE_MARKET,
  SYSTEM_PROMPT_FULL_OUTLINE_PRODUCT,
  generateFullOutlinePrompt,
} from '@/lib/prompts/generate-full-outline-from-skeleton';
import { InterviewService } from '@/services/interviews.service';

export const generateInterviewQuestions = async (req: Request, res: Response) => {
  console.log("generate-interview-questions request received");
  const body = req.body;

  console.warn('ã€OpenAI é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts:15', {
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1",
    requestBody: body
  });

  try {
    const baseCompletion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT,
        },
        {
          role: "user",
          content: generateQuestionsPrompt(body),
        },
      ],
      response_format: { type: "json_object" },
    });

    const basePromptOutput = baseCompletion.choices[0] || {};
    const content = basePromptOutput.message?.content;

    console.log("Interview questions generated successfully");

    res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error generating interview questions:", error);
    console.error('ã€OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts:49', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      requestBody: body
    });

    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

export const generateInterviewSessions = async (req: Request, res: Response) => {
  console.error("ğŸš€ğŸš€ğŸš€ generate-interview-sessions request received ğŸš€ğŸš€ğŸš€");
  const body = req.body;
  console.error("ğŸ“¦ Request body:", JSON.stringify(body, null, 2));
  const researchType = body.researchType || 'product';
  // ä¼˜å…ˆä½¿ç”¨ outline_debug_languageï¼ˆå¤§çº²è°ƒè¯•è¯­è¨€ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ languageï¼ˆè®¿è°ˆè¯­è¨€ï¼‰
  const debugLanguage = body.outline_debug_language || body.language || 'en-US';
  console.error("ğŸŒ Debug Language:", debugLanguage);
  console.error("ğŸŒ Interview Language:", body.language);

  // å°†è°ƒè¯•è¯­è¨€ä¼ é€’ç»™promptç”Ÿæˆå‡½æ•°
  const promptBody = {
    ...body,
    language: debugLanguage
  };

  let systemPrompt;
  let userPrompt;

  // æ ¹æ®ç ”ç©¶ç±»å‹é€‰æ‹©å¯¹åº”çš„ Prompt
  // æ³¨æ„ï¼šresearchType åªèƒ½æ˜¯ 'market' æˆ– 'product'ï¼ˆå‰ç«¯ç±»å‹é™åˆ¶ + åç«¯é»˜è®¤å€¼ï¼‰
  if (researchType === 'market') {
    systemPrompt = SYSTEM_PROMPT_MARKET_RESEARCH;
    userPrompt = generateMarketResearchSessionsPrompt(promptBody);
  } else {
    // é»˜è®¤ä½¿ç”¨ Product Research Prompt
    systemPrompt = SYSTEM_PROMPT_PRODUCT_RESEARCH;
    userPrompt = generateProductResearchSessionsPrompt(promptBody);
  }

  console.warn('ã€ç”Ÿæˆ Sessions - é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
    researchType,
    debugLanguage, // è®°å½•è°ƒè¯•è¯­è¨€
    interviewLanguage: body.language || 'N/A', // è®°å½•è®¿è°ˆè¯­è¨€
    customInstructions: body.customInstructions || 'none', // è®°å½•ä¸ªæ€§åŒ–å¤‡æ³¨
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1",
    requestBody: body
  });

  try {
    const baseCompletion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: userPrompt,
        },
      ],
      response_format: { type: "json_object" },
    });

    const basePromptOutput = baseCompletion.choices[0] || {};
    let content = basePromptOutput.message?.content;  // ğŸ”§ æ”¹ä¸º letï¼Œä»¥ä¾¿è¡¥å…¨æ—¶æ›´æ–°

    console.log(`Interview sessions (${researchType}) generated successfully`);

    // ğŸ” éªŒè¯ GPT å®é™…ç”Ÿæˆçš„æ•°é‡
    try {
      let parsedContent = JSON.parse(content || '{}');
      const actualCount = parsedContent.questions?.length || 0;
      const requestedCount = Math.min(body.number, 10);
      
      console.log('ğŸ“Š Session Count Verification:', {
        requested: requestedCount,
        actualGenerated: actualCount,
        match: actualCount === requestedCount ? 'âœ…' : 'âŒ',
        questions: parsedContent.questions?.map((q: string, i: number) => ({
          index: i + 1,
          preview: q.substring(0, 50) + '...'
        }))
      });
      
      if (actualCount !== requestedCount) {
        console.error(`âš ï¸âš ï¸âš ï¸ COUNT MISMATCH: Requested ${requestedCount} but GPT generated ${actualCount} sessions!`);
        console.error('ğŸ“ GPT åŸå§‹å›å¤ï¼ˆå®Œæ•´å†…å®¹ï¼‰ï¼š');
        console.error('==================== START ====================');
        console.error(content);
        console.error('==================== END ====================');
        
        // ğŸ”§ æ™ºèƒ½è¡¥å…¨ï¼šå¦‚æœæ•°é‡ä¸è¶³ï¼Œè®© GPT ç»§ç»­è¡¥å…¨
        if (actualCount < requestedCount) {
          const missing = requestedCount - actualCount;
          console.log(`ğŸ”„ è°ƒç”¨ GPT è¡¥å…¨å‰©ä½™ ${missing} ä¸ª sessions...`);
          
          try {
            const complementPrompt = `You previously generated ${actualCount} sessions for an interview guide, but the user requested ${requestedCount} sessions in total.

Here are the ${actualCount} sessions you already generated:
${JSON.stringify(parsedContent.questions, null, 2)}

**CRITICAL REQUIREMENT**:
You MUST now generate EXACTLY ${missing} MORE sessions (Session ${actualCount + 1} to Session ${requestedCount}) to complete the interview guide.

Requirements:
1. Continue from where you left off (start with Session ${actualCount + 1})
2. Generate EXACTLY ${missing} sessions - no more, no less
3. Maintain the same format and quality as the previous sessions
4. Ensure these new sessions naturally follow the previous ones
5. Each session should follow the established structure

Original research context:
- Research Type: ${researchType}
- Study Name: ${body.name}
- Research Objective: ${body.objective}
${body.context ? `- Additional Context: ${body.context}` : ''}

Output ONLY a JSON object with a "questions" array containing EXACTLY ${missing} new session strings.
Format: {"questions": ["session ${actualCount + 1} text", "session ${actualCount + 2} text", ...]}

DO NOT include the previous ${actualCount} sessions in your response.
ONLY generate the NEW ${missing} sessions.`;

            const complementResponse = await openaiClient.chat.completions.create({
              model: "gpt-4o",
              messages: [
                {
                  role: "system",
                  content: systemPrompt,
                },
                {
                  role: "user",
                  content: complementPrompt,
                },
              ],
              response_format: { type: "json_object" },
              temperature: 0.7,
            });

            const complementContent = complementResponse.choices[0]?.message?.content;
            const complementParsed = JSON.parse(complementContent || '{}');
            
            if (complementParsed.questions && Array.isArray(complementParsed.questions)) {
              console.log(`âœ… GPT è¡¥å…¨äº† ${complementParsed.questions.length} ä¸ª sessions`);
              // åˆå¹¶åŸå§‹å’Œè¡¥å…¨çš„ sessions
              parsedContent.questions = [...parsedContent.questions, ...complementParsed.questions];
              content = JSON.stringify(parsedContent);
              console.log(`âœ… æ€»è®¡ ${parsedContent.questions.length} ä¸ª sessions`);
            } else {
              console.error('âŒ GPT è¡¥å…¨å“åº”æ ¼å¼é”™è¯¯');
            }
          } catch (complementError: any) {
            console.error('âŒ GPT è¡¥å…¨å¤±è´¥:', complementError.message);
          }
        } else if (actualCount > requestedCount) {
          // å¦‚æœç”Ÿæˆå¤šäº†ï¼Œç›´æ¥æˆªæ–­
          console.log(`âœ‚ï¸ æˆªæ–­åˆ° ${requestedCount} ä¸ª sessions`);
          parsedContent.questions = parsedContent.questions.slice(0, requestedCount);
          content = JSON.stringify(parsedContent);
        }
      }
    } catch (e) {
      console.error('âŒ Failed to parse GPT response for verification:', e);
      console.error('ğŸ“ GPT åŸå§‹å›å¤ï¼ˆè§£æå¤±è´¥ï¼Œè¾“å‡ºåŸå§‹å†…å®¹ï¼‰ï¼š');
      console.error('==================== START ====================');
      console.error(content);
      console.error('==================== END ====================');
    }

    res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error generating interview sessions:", error);
    console.error('ã€ç”Ÿæˆ Sessions - OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      requestBody: body
    });

    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

/**
 * æœ¬åœ°åŒ–å¤§çº²æ¥å£
 * å°†è°ƒè¯•è¯­è¨€çš„åˆç¨¿å¤§çº²æœ¬åœ°åŒ–åˆ°ç›®æ ‡è®¿è°ˆè¯­è¨€
 */
export const localizeOutline = async (req: Request, res: Response) => {
  console.log("localize-outline request received");
  const body = req.body;

  const {
    draftOutline,
    targetLanguage,
    researchObjective,
    studyName,
    description
  } = body;

  // éªŒè¯å¿…éœ€å‚æ•°
  if (!draftOutline || !targetLanguage) {
    return res.status(400).json({
      error: "Missing required parameters",
      details: "draftOutline and targetLanguage are required"
    });
  }

  console.warn('ã€æœ¬åœ°åŒ–å¤§çº² - é…ç½®ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
    targetLanguage,
    studyName: studyName || 'N/A',
    description: description || 'N/A',  // æ·»åŠ  description æ—¥å¿—
    descriptionLength: description ? description.length : 0,  // description é•¿åº¦
    draftOutlineLength: Array.isArray(draftOutline) ? draftOutline.length : 'invalid',
    apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
    baseURL: process.env.OPENAI_API_BASE || "https://api.tu-zi.com/v1"
  });

  try {
    const completion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT_LOCALIZATION,
        },
        {
          role: "user",
          content: generateLocalizeOutlinePrompt({
            draftOutline,
            targetLanguage,
            researchObjective,
            studyName,
            description
          }),
        },
      ],
      response_format: { type: "json_object" },
      temperature: 0.7, // ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´è‡ªç„¶çš„è¡¨è¾¾
    });

    const output = completion.choices[0] || {};
    const content = output.message?.content;

    console.log(`âœ… Outline localized successfully to ${targetLanguage}`);

    // è§£æå¹¶éªŒè¯ OpenAI å“åº”
    try {
      const parsedContent = JSON.parse(content || '{}');
      console.log('ğŸ“ OpenAI Response Structure:', {
        hasQuestions: !!parsedContent.questions,
        questionsCount: parsedContent.questions?.length || 0,
        hasDescription: !!parsedContent.description,
        descriptionPreview: parsedContent.description ?
          parsedContent.description.substring(0, 100) + '...' :
          'MISSING'
      });

      if (!parsedContent.description) {
        console.warn('âš ï¸ WARNING: OpenAI did not return description field!');
      }
    } catch (e) {
      console.error('âŒ Failed to parse OpenAI response:', e);
    }

    return res.status(200).json({
      response: content,
    });
  } catch (error: any) {
    console.error("Error localizing outline:", error);
    console.error('ã€æœ¬åœ°åŒ–å¤§çº² - OpenAI API é”™è¯¯ã€‘ï¼š>>>>>>>>>>>> questions.controller.ts', {
      error: error.message,
      stack: error.stack,
      apiKey: process.env.OPENAI_API_KEY ? 'exists' : 'missing',
      targetLanguage,
      requestBody: body
    });

    return res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

// ============================================
// Two-Step Outline Generation APIs
// ============================================

/**
 * Step 1: Generate Outline Skeleton
 * POST /api/outlines/skeleton
 * æ³¨æ„ï¼šè¿™ä¸ª API ä¸éœ€è¦ interview_idï¼Œåªéœ€è¦åŸºæœ¬ä¿¡æ¯å³å¯ç”Ÿæˆéª¨æ¶
 */
export const generateOutlineSkeleton = async (req: Request, res: Response) => {
  console.log("ğŸ¯ generate-outline-skeleton request received");
  const { name, objective, context = '', session_count, duration_minutes, draft_language, researchType = 'product', manualSessions } = req.body;

  console.log("ğŸ“‹ Generating skeleton:", {
    name,
    objective: objective?.substring(0, 100) + '...',
    session_count,
    duration_minutes,
    draft_language,
    researchType,
    manualSessions: manualSessions?.length || 0
  });

  try {
    // è°ƒç”¨ Step 1 Prompt ç”Ÿæˆéª¨æ¶ï¼ˆä¸éœ€è¦ interview_idï¼‰
    const completion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      temperature: 0.7,
      messages: [
        {
          role: "system",
          content: SYSTEM_PROMPT_SKELETON,
        },
        {
          role: "user",
          content: generateSkeletonPrompt({
            objective: objective || '',
            context: context || '',
            session_count,
            duration_minutes,
            language: draft_language,
            researchType: researchType || 'product',
            manualSessions: manualSessions || []
          }),
        },
      ],
      response_format: { type: "json_object" },
    });

    const content = completion.choices[0]?.message?.content;
    if (!content) {
      throw new Error("No content returned from OpenAI");
    }

    const skeleton = JSON.parse(content);

    // ğŸ†• ä¸ºæ¯ä¸ª session æ·»åŠ  ai_suggested_depth_levelï¼ˆä¿å­˜ AI æœ€åˆå»ºè®®çš„ depth_levelï¼‰
    if (skeleton.sessions && Array.isArray(skeleton.sessions)) {
      skeleton.sessions = skeleton.sessions.map((session: any) => ({
        ...session,
        ai_suggested_depth_level: session.depth_level || 'medium' // ä¿å­˜ AI å»ºè®®çš„ depth_level
      }));
    }

    // ğŸ†• ç¡®ä¿ metadata.draft_language å­˜åœ¨ï¼ˆå¦‚æœ AI æ²¡æœ‰ç”Ÿæˆï¼Œæ‰‹åŠ¨æ·»åŠ ï¼‰
    if (!skeleton.metadata) {
      skeleton.metadata = {};
    }
    if (!skeleton.metadata.draft_language) {
      skeleton.metadata.draft_language = draft_language;
      console.log('âš ï¸ AI did not include draft_language in metadata, manually added:', draft_language);
    }

    console.log("âœ… Skeleton generated successfully:", {
      total_sessions: skeleton.metadata?.total_sessions,
      draft_language: skeleton.metadata?.draft_language
    });

    res.status(200).json({
      skeleton,
      status: 'skeleton_generated'
    });

  } catch (error: any) {
    console.error("âŒ Error generating skeleton:", error);
    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

/**
 * Step 2: Update Skeleton (User edits)
 * PATCH /api/outlines/:id/skeleton
 */
export const updateOutlineSkeleton = async (req: Request, res: Response) => {
  console.log("ğŸ“ update-outline-skeleton request received");
  const { id } = req.params;
  const { skeleton } = req.body;

  try {
    await InterviewService.updateInterview({
      outline_skeleton: skeleton
    }, id);

    console.log("âœ… Skeleton updated successfully");

    res.status(200).json({
      skeleton,
      status: 'skeleton_generated'
    });

  } catch (error: any) {
    console.error("âŒ Error updating skeleton:", error);
    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};

/**
 * Step 3: Generate Full Outline from Skeleton
 * POST /api/outlines/:id/full-outline
 */
export const generateFullOutlineFromSkeleton = async (req: Request, res: Response) => {
  console.log("ğŸš€ generate-full-outline-from-skeleton request received");
  const { id } = req.params;

  try {
    // 1. è·å–éª¨æ¶å’Œ interview ä¿¡æ¯
    const interview = await InterviewService.getInterviewById(id);

    if (!interview) {
      return res.status(404).json({ error: "Interview not found" });
    }

    if (!interview.outline_skeleton) {
      return res.status(400).json({ error: "Skeleton not found. Please generate skeleton first." });
    }

    console.log("ğŸ“‹ Generating full outline from skeleton:", {
      interview_id: id,
      skeleton_sessions: interview.outline_skeleton.sessions.length,
      draft_language: interview.outline_skeleton.metadata?.draft_language,
      outline_debug_language: (interview as any).outline_debug_language
    });

    // 2. è°ƒç”¨ Step 2 Prompt ç”Ÿæˆå®Œæ•´å¤§çº²
    const researchType = (interview as any).researchType || 'product';
    const systemPrompt = researchType === 'market'
      ? SYSTEM_PROMPT_FULL_OUTLINE_MARKET
      : SYSTEM_PROMPT_FULL_OUTLINE_PRODUCT;

    const completion = await openaiClient.chat.completions.create({
      model: "gpt-4o",
      temperature: 0.7,
      messages: [
        {
          role: "system",
          content: systemPrompt,
        },
        {
          role: "user",
          content: generateFullOutlinePrompt({
            skeleton: interview.outline_skeleton,
            objective: interview.objective || '',
            context: (interview as any).context || '',
            researchType: researchType
          }),
        },
      ],
      response_format: { type: "json_object" },
    });

    const content = completion.choices[0]?.message?.content;
    if (!content) {
      throw new Error("No content returned from OpenAI");
    }

    console.log("ğŸ“„ Raw OpenAI response:", content.substring(0, 500) + '...');

    const fullOutline = JSON.parse(content);

    console.log("ğŸ“Š Parsed fullOutline:", {
      questionsCount: fullOutline.questions?.length || 0,
      descriptionLength: fullOutline.description?.length || 0,
      firstQuestion: fullOutline.questions?.[0],
      lastQuestion: fullOutline.questions?.[fullOutline.questions?.length - 1]
    });

    // 3. å¤„ç†æ–°çš„æ•°æ®ç»“æ„ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
    let questionsToSave;
    if (Array.isArray(fullOutline.questions) && fullOutline.questions.length > 0) {
      // æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ ¼å¼ï¼ˆå¯¹è±¡æ•°ç»„ï¼‰
      if (typeof fullOutline.questions[0] === 'object' && fullOutline.questions[0].session_text) {
        // æ–°æ ¼å¼ï¼šä¿å­˜å®Œæ•´å¯¹è±¡ï¼ˆåŒ…å« depth_levelï¼‰
        questionsToSave = fullOutline.questions;
        console.log('âœ… Using new format with depth_level:', fullOutline.questions.map((q: any) => q.depth_level));
      } else {
        // æ—§æ ¼å¼ï¼šå­—ç¬¦ä¸²æ•°ç»„ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼ï¼ˆé»˜è®¤ mediumï¼‰
        questionsToSave = fullOutline.questions.map((sessionText: string) => ({
          session_text: sessionText,
          depth_level: 'medium'
        }));
        console.log('âš ï¸ Converting old format to new format (default depth_level: medium)');
      }
    } else {
      questionsToSave = [];
    }

    console.log("ğŸ’¾ Questions to save:", {
      count: questionsToSave.length,
      sessions: questionsToSave.map((q: any, idx: number) => ({
        index: idx,
        session_text_preview: q.session_text?.substring(0, 50) + '...',
        depth_level: q.depth_level
      }))
    });

    // 4. ä¿å­˜å®Œæ•´å¤§çº²
    await InterviewService.updateInterview({
      draft_outline: questionsToSave,
      description: fullOutline.description,
      outline_generation_status: 'draft_generated'
    }, id);

    console.log("âœ… Full outline generated successfully");

    res.status(200).json({
      draft_outline: questionsToSave,
      description: fullOutline.description,
      status: 'draft_generated'
    });

  } catch (error: any) {
    console.error("âŒ Error generating full outline:", error);
    res.status(500).json({
      error: "internal server error",
      details: error.message || "Unknown error"
    });
  }
};
