# FoloUp 总结模块测试指南

> 按照以下步骤测试新实现的总结功能

---

## 📋 前置准备

### 1. 运行数据库Migration

**步骤**：
1. 打开Supabase Dashboard：https://supabase.com/dashboard
2. 选择你的项目
3. 点击左侧菜单的 "SQL Editor"
4. 点击 "New query"
5. 复制 `backend/migrations/001_add_summary_fields.sql` 的全部内容
6. 粘贴到SQL编辑器
7. 点击 "Run" 执行

**验证**：
```sql
-- 检查response表新字段
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'response' 
AND column_name IN ('key_insights', 'important_quotes');

-- 检查interview表新字段
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'interview' 
AND column_name IN ('executive_summary', 'objective_deliverables', 'cross_interview_insights', 'evidence_bank');
```

应该看到所有新字段都已添加。

---

## 🧪 测试1：单访谈深度总结

### 目标
验证访谈结束后自动生成Key Insights和Important Quotes

### 步骤

1. **创建测试Study**：
   - 访问 http://localhost:8089/dashboard
   - 点击 "Create New Study"
   - 填写信息：
     - Name: "测试访谈总结功能"
     - Objective: "了解用户对AI写作工具的需求和痛点，生成3个产品改进建议"
     - Description: "测试用例"
   - 创建Study

2. **进行测试访谈**：
   - 复制Study的访谈链接
   - 在新标签页打开链接
   - 完成一次完整的访谈（建议5-10分钟）
   - 确保访谈正常结束

3. **检查单访谈页面**：
   - 回到Dashboard
   - 点击刚才的Study
   - 点击访谈记录，进入单访谈详情页
   - 向下滚动，应该看到：
     - ✅ **Key Insights** 卡片（3-5条洞察）
     - ✅ **Important Quotes** 卡片（5-10条引用，带时间戳）

### 预期结果

**Key Insights示例**：
```
Insight 1 [User Need]
用户希望AI能够理解上下文，而不是简单地生成文本

Insight 2 [Pain Point]
当前工具生成的内容过于机械，缺乏人性化

Insight 3 [Behavior]
用户倾向于先用AI生成草稿，然后手动修改
```

**Important Quotes示例**：
```
[Participant] 00:03:45
"我希望AI能帮我改，但我要能看到它改了什么"
Context: 讨论AI辅助编辑功能时
```

### 故障排查

**如果没有生成Key Insights和Important Quotes**：

1. 检查后端日志：
   ```bash
   # 查看Terminal 18的输出
   # 应该看到类似的日志：
   # 🔍 [Interview Summary] Starting generation for call: xxx
   # ✅ [Interview Summary] Generated successfully
   ```

2. 检查数据库：
   ```sql
   SELECT call_id, key_insights, important_quotes 
   FROM response 
   WHERE call_id = 'YOUR_CALL_ID';
   ```

3. 检查API调用：
   - 打开浏览器开发者工具（F12）
   - 切换到 Network 标签
   - 刷新页面
   - 查找 `/api/analytics/generate` 请求
   - 检查响应是否包含 key_insights 和 important_quotes

---

## 🧪 测试2：Study级别总结

### 目标
验证"Generate Insights"按钮能够生成Study级别的深度洞察

### 步骤

1. **进行多次访谈**：
   - 在同一个Study中，至少进行3次访谈
   - 确保每次访谈都正常结束
   - 每次访谈的内容应该有所不同

2. **生成Study Insights**：
   - 回到Dashboard
   - 点击Study，进入Study详情页
   - 应该看到两个Tab：
     - Overview（默认）
     - Study Insights
   - 点击右上角的 "Generate Insights" 按钮
   - 等待生成（可能需要10-30秒）

3. **检查Study Insights Tab**：
   - 自动切换到 "Study Insights" Tab
   - 应该看到：
     - ✅ **Executive Summary**（一段话总结）
     - ✅ **Objective Deliverables**（根据Study Objective生成的产出）
     - ✅ **Cross-Interview Insights**（5-8条跨访谈洞察）
     - ✅ **Supporting Evidence**（每条洞察的用户引用）

### 预期结果

**Executive Summary示例**：
```
本次研究共访谈了3位用户，主要发现用户对AI写作工具的核心需求是"可控性"和"透明度"。
用户普遍担心AI生成的内容过于机械，希望能够保留人性化的表达。
基于这些发现，我们提出了3个产品改进建议。
```

**Objective Deliverables示例**（因为Objective提到"3个产品改进建议"）：
```
Key Deliverables

1. 增强AI编辑的可视化反馈
   - 高亮显示AI修改的部分
   - 提供"接受/拒绝"按钮
   - 保留修改历史记录

2. 优化AI生成内容的人性化
   - 训练模型理解用户的写作风格
   - 提供多种语气选项（正式/轻松/专业）
   - 支持自定义词汇偏好

3. 添加上下文理解功能
   - 分析整篇文章的主题和结构
   - 根据上下文调整生成内容
   - 支持多轮对话式编辑
```

**Cross-Interview Insights示例**：
```
Insight 1 [High Importance]
所有用户都提到了"可控性"问题，担心AI完全接管写作过程

Insight 2 [Medium Importance]
用户倾向于将AI作为"助手"而非"替代品"

Insight 3 [High Importance]
透明度是用户信任AI工具的关键因素
```

### 故障排查

**如果点击"Generate Insights"后没有反应**：

1. 检查浏览器控制台（F12 → Console）：
   - 查看是否有错误信息

2. 检查Network请求：
   - F12 → Network
   - 查找 `/api/analytics/study-summary` 请求
   - 检查响应状态码和内容

3. 检查后端日志：
   ```bash
   # 应该看到类似的日志：
   # 🔍 [Study Summary] Starting generation for interview: xxx
   # 🎯 [Study Summary] Stage 1: Extracting deliverables...
   # ✅ [Study Summary] Deliverables extracted
   # 📝 [Study Summary] Stage 2: Generating summary...
   # ✅ [Study Summary] Generated successfully
   ```

4. 检查数据库：
   ```sql
   SELECT id, executive_summary, objective_deliverables, cross_interview_insights 
   FROM interview 
   WHERE id = 'YOUR_INTERVIEW_ID';
   ```

---

## 🧪 测试3：编辑功能

### 目标
验证用户可以编辑AI生成的Executive Summary

### 步骤

1. 在Study Insights Tab中，找到 "Executive Summary" 卡片
2. 点击右上角的 "Edit" 按钮（铅笔图标）
3. 修改文本内容
4. 点击 "Save" 按钮
5. 刷新页面，检查修改是否保存

### 预期结果

- ✅ 点击Edit后，文本变为可编辑的Textarea
- ✅ 显示Save和Cancel按钮
- ✅ 点击Save后，内容更新
- ✅ 点击Cancel后，恢复原内容

### 注意
目前编辑功能只更新了前端状态，还没有连接到后端API。如果需要持久化保存，需要添加API调用。

---

## 🧪 测试4：UI/UX检查

### 检查项

**单访谈页面**：
- [ ] Key Insights卡片样式正确
- [ ] 分类标签颜色正确（Need=蓝色，Pain Point=红色等）
- [ ] Important Quotes显示时间戳
- [ ] 引用文本用斜体显示
- [ ] 空状态提示正确显示
- [ ] 移动端响应式正常

**Study页面**：
- [ ] Tabs切换流畅
- [ ] "Generate Insights"按钮位置合理
- [ ] 加载状态显示正确（转圈图标）
- [ ] 卡片布局美观
- [ ] 颜色和间距一致
- [ ] 空状态提示正确显示

---

## 📊 测试数据建议

为了更好地测试功能，建议使用以下测试场景：

### 场景1：产品改进研究
- **Objective**: "了解用户对移动应用的使用体验，生成3个优先级最高的改进建议"
- **访谈数量**: 3-5次
- **预期Deliverables**: 3个改进建议，按优先级排序

### 场景2：付费意愿调研
- **Objective**: "调研用户对高级功能的付费意愿，确定合理的定价区间"
- **访谈数量**: 5-8次
- **预期Deliverables**: 付费意愿分析，包含价格区间和影响因素

### 场景3：用户痛点挖掘
- **Objective**: "识别用户在使用过程中的前5大痛点，并分析根本原因"
- **访谈数量**: 4-6次
- **预期Deliverables**: 5个痛点，按严重程度排序，附带根本原因分析

---

## ✅ 测试完成检查清单

完成以下所有项目后，总结模块测试通过：

### 数据库
- [ ] Migration成功执行
- [ ] 所有新字段已添加
- [ ] 索引创建成功

### 单访谈功能
- [ ] Key Insights自动生成
- [ ] Important Quotes自动生成
- [ ] 数据正确保存到数据库
- [ ] UI正确显示

### Study功能
- [ ] "Generate Insights"按钮正常工作
- [ ] Executive Summary生成正确
- [ ] Objective Deliverables动态生成
- [ ] Cross-Interview Insights生成正确
- [ ] Evidence Bank显示正确
- [ ] 数据正确保存到数据库

### UI/UX
- [ ] Tabs切换正常
- [ ] 加载状态正确
- [ ] 空状态提示正确
- [ ] 编辑功能正常
- [ ] 移动端响应式正常

---

## 🐛 常见问题

### Q1: 访谈结束后没有生成Key Insights
**A**: 检查后端日志，确认`generateInterviewSummary`是否被调用。如果没有，可能是`generateAnalytics`集成有问题。

### Q2: "Generate Insights"按钮点击后一直转圈
**A**: 检查后端日志和Network请求，可能是AI API调用超时或失败。

### Q3: Objective Deliverables结构不符合预期
**A**: 这是正常的，因为deliverables是动态生成的。如果结构完全错误，可能需要优化prompt。

### Q4: 编辑后刷新页面，修改丢失
**A**: 目前编辑功能只更新前端状态，需要添加API调用来持久化保存。

---

## 📞 需要帮助？

如果遇到问题，请提供以下信息：
1. 具体的错误信息（浏览器控制台 + 后端日志）
2. 复现步骤
3. 预期结果 vs 实际结果
4. 相关的数据库查询结果

祝测试顺利！🎉

