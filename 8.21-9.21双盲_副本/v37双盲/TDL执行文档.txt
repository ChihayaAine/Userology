一、推进新访谈ab test：产品新旧版本感受变化调研（V037）

产品新版本改进调研：
    新旧版本感受变化
    新版本功能需求程度排序（最有用的前几个，三个，rank）
    挖掘未来的需求和产品机会点

1. 跟产品团队对齐输入，同时优化素材流结构，尽量能做到无人化，客观化
    将素材A-D也自动化：
        访谈/调研目标：MRD，一定要可量化、对齐
        产品背景
        竞品：AI自动web search获取
        访谈用户画像
    输出：
        一个标准化的AI访谈操作手册

2. 使用优化后的链条跑完AI侧的新版本改进调研（1.新用户；2.老用户）
    输入：
        经对齐的访谈目标与相关产品文档
    过程产出：
        素材B-L
        3条AI访谈记录
        AI提炼的Action plan（3选做，3必做）
    最终产出：
        格式化的过程产出（3条强烈建议修改 + 3条option修改）

3. 由李老师作为裁判，评价ai访谈洞察质量
    输出：
        结论，无人化可行性

4. 通过问卷调查ai访谈用户体验
问卷：https://www.surveycake.com/s/9GNqr
样本数：4（台湾用户）
调研结果总结：
遵循产品团队的建议后有些问题依旧出现：
    1. 模型回复速度依旧慢（responsiveness调整到最高，却依旧高延迟）
    2. 即兴追问深度不够（section notes中备注效果一般）
    3. acknowledgements死板，缺乏温度：基本只说“明白了”、“了解了”和“好的”（section notes中备注效果一般）
    4. 语音识别精度低，导致ai“听不清用户说的话”（这个以前出现的比较少，可能是台湾用户表达习惯与“语言设定-简体中文”不符合）
    5. 中英混杂时，似乎只会用预设语言来识别用户输入（若访谈语言为中文，除了“名词”以外几乎无法识别英文）
    6. 说话节奏有时会突然加快（出现较少）

用户体验评分：AI平均7分，人类平均8分（各去除1个outlier），整体ai访谈体验中等偏上
用户偏好：75%更喜欢人类访谈（8分 vs AI的7分）
主要优势：访谈时间灵活、对话无压力（但也有人提到由于语音识别不清晰导致要格外注意措辞）
AI访谈局限：一个study对不同用户都是标准化流程，没办法导入访谈用户的背景资料判断跳过哪些问题、针对性对话
综合感受：Userology的付费模型相较于免费版模型无太大差异

二、开源调研
Foloup：
主要关注点：
1. 短期使用体验：时间延迟、语音流畅；
    语音流畅，延迟低。
2. 长期稳定性：语音稳定（不要面谈一会儿软件自己崩了、持续时长）
    硬件测试（30min）：
    在foloup框架内执行
    测试结果：
    测试1: 用豆包语音模式和foloup对话，中间foloup在10分钟左右体现出总结/结束对话的趋势，但被我打断继续话题了。最后在19分钟时猝不及防结束了对话（“Seems like you're ready to wrap up. Feel free to reach out anytime for more discussions. Have a great day."）
    测试2: 用gpt4o（输入了要求：尽可能延长对话时间）语音模式和foloup对话，过程一直很稳定，没有尝试结束对话的趋势。最后在35分钟时挂断
3. prompt调整让他能够做interview（优先级后置）
    可以实现，只需要在语音agent平台调整prompt就好。

Prepwise：
语音配置一切正常（Vapi平台），但是用户无法自定义大纲和问题，只能在Voice Agent配置后台改系统prompt



三、AI面试工具探索
试试能不能把userology通过改prompt做成面试工具（跟userology guideline会不会冲突？），我们自己做总结
我们主要需要中间部分，面谈（因为我们自己语音做不了）。前面（大纲）后面（总结）都可以直接用大模型

测试结果：
深入追问的能力基本过关了，但是问题还是在于整体灵活度不够。可以尽可能减少预设问题数量，将自由度放到最高。
局限：
    1. 似乎没有联网，导致对前沿技术缺乏深入了解（如NSA）。若没有提前提供相关背景信息，在实际面试场景下它基于被试者回答的追问针对性会较弱。
    2. 对不同受试者都是标准化流程，没办法根据访谈用户的cv/背景资料来针对性提问

